{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e4b7f1",
   "metadata": {},
   "source": [
    "# LAB | Audio Classification CNN\n",
    "\n",
    "## Introduction\n",
    "This notebook guides you through audio classification using a CNN model on the Kaggle audio dataset. You will:\n",
    "- Load and explore the dataset\n",
    "- Apply various preprocessing methods (MFCC, Mel spectrogram, Chromagram)\n",
    "- Build and train a CNN classifier on these features\n",
    "- Experiment with preprocessing parameters to improve results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bf7215",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02792073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install librosa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e276e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceeb0285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/warcoder/cats-vs-dogs-vs-birds-audio-classification?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13.2M/13.2M [00:07<00:00, 1.98MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\vivobook\\.cache\\kagglehub\\datasets\\warcoder\\cats-vs-dogs-vs-birds-audio-classification\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"warcoder/cats-vs-dogs-vs-birds-audio-classification\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2f756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_in_dir = os.listdir(path)\n",
    "print(files_in_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: create a dataframe\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a9982e",
   "metadata": {},
   "source": [
    "## Step 2: Audio Preprocessing Functions\n",
    "\n",
    "Define functions for feature extraction you will experiment with:\n",
    "\n",
    "- MFCC\n",
    "- Spectrogram\n",
    "- Chromogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d92f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: Your_Code_Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53127c3f",
   "metadata": {},
   "source": [
    "## Step 3: Visualize Audio Features\n",
    "\n",
    "Visualize extracted features for a sample audio file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147235b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: Your_Code_Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16531f50",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Data for CNN\n",
    "\n",
    "Extract features for all files and prepare train/test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a4012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: Your_Code_Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5363a3f5",
   "metadata": {},
   "source": [
    "## Step 5: Define CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719e3601",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: Your_Code_Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfaf6e7",
   "metadata": {},
   "source": [
    "## Step 6: Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: Your_Code_Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef8f2de",
   "metadata": {},
   "source": [
    "## Step 7: Experimentation\n",
    "\n",
    "- Try using Mel Spectrogram and Chromagram as features instead of MFCC by changing the `feature_extractor` function in the data preparation.\n",
    "- Modify parameters like `n_mfcc`, `n_mels`, `max_len`.\n",
    "- Tune CNN architecture (add layers, change filters).\n",
    "- Compare results and report observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03303447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
